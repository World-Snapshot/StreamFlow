#!/usr/bin/env python3
"""
Test42: PeRFlowçœŸæ­£çš„æ‰¹é‡å»å™ªå¼€å…³æµ‹è¯•

åŸºäºtest25çš„å®Œæ•´ç»“æ„ï¼Œæ·»åŠ çœŸæ­£çš„æµæ°´çº¿æ‰¹é‡å»å™ªåŠŸèƒ½ï¼š
- ä¿æŒtest25çš„æ‰€æœ‰åŠŸèƒ½ï¼ˆå¸§ç¼“å†²æµ‹è¯•ã€å¤šæ¨¡å¼ç”Ÿæˆç­‰ï¼‰
- æ·»åŠ çœŸæ­£çš„æ‰¹é‡å»å™ªå¼€å…³
- å¯ä»¥å¯¹æ¯”åŸå§‹StreamFlow vs æµæ°´çº¿æ‰¹é‡StreamFlowçš„æ€§èƒ½å’Œè´¨é‡
"""

import torch, torchvision
from src.scheduler_perflow import PeRFlowScheduler
import time
import os

from diffusers import AutoencoderTiny, StableDiffusionPipeline

# å¯¼å…¥ä¸åŒçš„StreamFlowå®ç°
from src.streamflow import StreamFlow  # åŸå§‹ç‰ˆæœ¬
from src.streamflow.pipeline_batch_pipeline import PipelineBatchStreamFlow  # æµæ°´çº¿æ‰¹é‡ç‰ˆæœ¬
from src.streamflow.image_utils import postprocess_image


def run_perflow_frame_buffer_test():
    """
    ä½¿ç”¨StreamFlowè¿›è¡ŒPeRFlowå¸§ç¼“å†²æµ‹è¯•
    åŸºäºtest25ï¼Œæ·»åŠ çœŸæ­£çš„æ‰¹é‡å»å™ªåŠŸèƒ½
    æµ‹è¯•ä¸åŒframe_buffer_sizeå¯¹æ€§èƒ½å’Œè´¨é‡çš„å½±å“
    """
    print("ğŸš€ PeRFlow + StreamFlow å¸§ç¼“å†²æµ‹è¯• (çœŸæ­£çš„æ‰¹é‡å»å™ªç‰ˆ)")
    print("=" * 60)
    
    # é…ç½®é€‰é¡¹ï¼ˆåŸºäºtest25ï¼‰
    USE_TINY_VAE = False  # è®¾ä¸ºTrueå¯è¿›ä¸€æ­¥åŠ é€Ÿï¼Œä½†ä¼šè½»å¾®å½±å“è´¨é‡
    VAE_DECODE_METHOD = "normalize"  # "normalize" æˆ– "dynamic"
    ACCELERATION = "xformers"  # xformers, tensorrt, none
    
    # æ–°å¢ï¼šå¸§ç¼“å†²å’Œç›¸å…³è®¾ç½®
    FRAME_BUFFER_SIZE = 1  # å¸§ç¼“å†²å¤§å°ï¼š1=æ— ç¼“å†²ï¼Œ2-8=å¤šå¸§ç¼“å†²
    USE_DENOISING_BATCH = True  # æ‰¹é‡é™å™ªï¼šä¿æŒåŸæœ‰è®¾ç½®
    DO_ADD_NOISE = True  # æ·»åŠ å™ªå£°ï¼šTrue=æ ‡å‡†æ¨¡å¼ï¼ŒFalse=å¿«é€Ÿæ¨¡å¼
    
    # ğŸš€ å…³é”®æ–°å¢ï¼šçœŸæ­£çš„æ‰¹é‡å»å™ªå¼€å…³
    USE_REAL_BATCH_DENOISING = True  # True=æµæ°´çº¿æ‰¹é‡å»å™ªï¼ŒFalse=åŸå§‹StreamFlow
    
    print(f"ğŸ”§ é…ç½®:")
    print(f"   VAEç±»å‹: {'TinyVAE' if USE_TINY_VAE else 'åŸå§‹VAE'}")
    print(f"   è§£ç æ–¹æ³•: {VAE_DECODE_METHOD}")
    print(f"   åŠ é€Ÿæ–¹æ³•: {ACCELERATION}")
    print(f"   å¸§ç¼“å†²å¤§å°: {FRAME_BUFFER_SIZE} ({'æ— ç¼“å†²' if FRAME_BUFFER_SIZE == 1 else f'{FRAME_BUFFER_SIZE}å¸§ç¼“å†²'})")
    print(f"   æ‰¹é‡é™å™ª: {'å¯ç”¨(StreamFlowä¼˜åŒ–)' if USE_DENOISING_BATCH else 'ç¦ç”¨'}")
    print(f"   æ·»åŠ å™ªå£°: {'å¯ç”¨' if DO_ADD_NOISE else 'ç¦ç”¨'}")
    print(f"   ğŸ¯ çœŸæ­£æ‰¹é‡å»å™ª: {'âœ… å¯ç”¨(æµæ°´çº¿å¹¶è¡Œ)' if USE_REAL_BATCH_DENOISING else 'âŒ ç¦ç”¨(åŸå§‹StreamFlow)'}")
    
    # å¸§ç¼“å†²è¯´æ˜ï¼ˆä¿æŒtest25çš„é€»è¾‘ï¼‰
    if FRAME_BUFFER_SIZE > 1:
        print(f"   ğŸ’¡ å¸§ç¼“å†²æ•ˆæœ: å¯èƒ½æé«˜æµå¼ç”Ÿæˆçš„æµç•…åº¦å’Œä¸€è‡´æ€§")
    else:
        print(f"   ğŸ’¡ æ— å¸§ç¼“å†²: æ¯å¸§ç‹¬ç«‹ç”Ÿæˆï¼Œå»¶è¿Ÿæœ€ä½")
    
    # æ‰¹é‡å»å™ªè¯´æ˜
    if USE_REAL_BATCH_DENOISING:
        print(f"\nğŸš€ æµæ°´çº¿æ‰¹é‡å»å™ªåŸç†:")
        print(f"   - 4å¼ ä¸åŒå›¾ç‰‡åŒæ—¶å¤„äºä¸åŒå»å™ªé˜¶æ®µ")
        print(f"   - 1æ¬¡UNetè°ƒç”¨å¤„ç†æ‰€æœ‰é˜¶æ®µï¼ˆ4xæ•ˆç‡æå‡ï¼‰")
        print(f"   - ä¿æŒPeRFlowç®—æ³•å®Œæ•´æ€§")
        print(f"   - ç‰¹åˆ«é€‚åˆè¿ç»­ç”Ÿæˆåœºæ™¯")
    else:
        print(f"\nğŸ“Š ä½¿ç”¨åŸå§‹StreamFlow:")
        print(f"   - ä¼ ç»Ÿé€æ­¥å»å™ªå¤„ç†")
        print(f"   - æ¯å¼ å›¾ç‰‡4æ¬¡UNetè°ƒç”¨")
        print(f"   - ä¸test25å®Œå…¨ç›¸åŒçš„è¡Œä¸º")
    
    # åŠ è½½PeRFlowæ¨¡å‹
    print(f"\nğŸ“¦ åŠ è½½PeRFlowæ¨¡å‹...")
    pipe = StableDiffusionPipeline.from_pretrained(
        "hansyan/perflow-sd15-dreamshaper", 
        torch_dtype=torch.float16
    )
    
    # è®¾ç½®PeRFlowè°ƒåº¦å™¨
    pipe.scheduler = PeRFlowScheduler.from_config(
        pipe.scheduler.config, 
        prediction_type="diff_eps", 
        num_time_windows=4
    )
    pipe.to("cuda", torch.float16)
    
    # å¯é€‰ï¼šä½¿ç”¨TinyVAEåŠ é€Ÿ
    if USE_TINY_VAE:
        print("ğŸ”„ åŠ è½½TinyVAE...")
        pipe.vae = AutoencoderTiny.from_pretrained("madebyollin/taesd").to(
            device=pipe.device, dtype=pipe.dtype
        )
    
    # ğŸ¯ å…³é”®ï¼šæ ¹æ®å¼€å…³é€‰æ‹©StreamFlowå®ç°
    if USE_REAL_BATCH_DENOISING:
        print("ğŸš€ åˆ›å»ºæµæ°´çº¿æ‰¹é‡StreamFlow...")
        stream = PipelineBatchStreamFlow(
            pipe,
            t_index_list=[0, 1, 2, 3],  # PeRFlowçš„4ä¸ªæ—¶é—´æ­¥ [0, 1, 2, 3]ï¼Œä½¿ç”¨49è¿™ç§æ—¶é—´æ­¥ä¼¼ä¹å¯ä»¥æå‡è´¨é‡ï¼š[0, 12, 24, 49]ï¼›ä½†æ˜¯0 1 2 3å¯¹äºcfgä¸ºnoneæ—¶æ•ˆæœéå¸¸å¥½
            torch_dtype=torch.float16,
            frame_buffer_size=FRAME_BUFFER_SIZE,  # å…³é”®ï¼šå¯ç”¨å¸§ç¼“å†²
            cfg_type="none",  # none, full, self, initializeï¼›I usually use none and full
            use_pipeline_batch=True,  # å¯ç”¨æµæ°´çº¿æ‰¹é‡å»å™ª
            vae_decode_method=VAE_DECODE_METHOD,  # ä¼˜åŒ–çš„è§£ç æ–¹æ³•
            do_add_noise=DO_ADD_NOISE,  # æ˜¯å¦æ·»åŠ å™ªå£°
        )
    else:
        print("ğŸ“Š åˆ›å»ºåŸå§‹StreamFlowï¼ˆä¸test25ç›¸åŒï¼‰...")
        # åˆ›å»ºStreamFlowï¼ˆæˆ‘ä»¬çš„ä¼˜åŒ–ç‰ˆæœ¬ï¼‰- å¯ç”¨å¸§ç¼“å†²
        stream = StreamFlow(
            pipe,
            t_index_list=[0, 1, 2, 3],  # PeRFlowçš„4ä¸ªæ—¶é—´æ­¥ [0, 1, 2, 3]ï¼Œä½¿ç”¨49è¿™ç§æ—¶é—´æ­¥ä¼¼ä¹å¯ä»¥æå‡è´¨é‡ï¼š[0, 12, 24, 49]ï¼›ä½†æ˜¯0 1 2 3å¯¹äºcfgä¸ºnoneæ—¶æ•ˆæœéå¸¸å¥½
            torch_dtype=torch.float16,
            frame_buffer_size=FRAME_BUFFER_SIZE,  # å…³é”®ï¼šå¯ç”¨å¸§ç¼“å†²
            cfg_type="none",  #none, full, self, initializeï¼›I usually use none and full
            use_original_scheduler=True,  # ä½¿ç”¨PeRFlowåŸç”Ÿè°ƒåº¦å™¨
            vae_decode_method=VAE_DECODE_METHOD,  # ä¼˜åŒ–çš„è§£ç æ–¹æ³•
            do_add_noise=DO_ADD_NOISE,  # æ˜¯å¦æ·»åŠ å™ªå£°
        )
    
    # å¯ç”¨åŠ é€Ÿ
    if ACCELERATION == "xformers":
        pipe.enable_xformers_memory_efficient_attention()
        print("âš¡ å¯ç”¨xformersåŠ é€Ÿ")
    
    # æµ‹è¯•æç¤ºè¯
    prompts_list = ["A man with brown skin, a beard, and dark eyes"]
    prompt = "RAW photo, 8k uhd, dslr, high quality, film grain, highly detailed, masterpiece; " + prompts_list[0]
    neg_prompt = "distorted, blur, smooth, low-quality, warm, haze, over-saturated, high-contrast, out of focus, dark"
    
    print(f"\nğŸ“ æç¤ºè¯: {prompt}")
    
    # é¢„çƒ­é˜¶æ®µ
    print(f"\nğŸ”¥ é¢„çƒ­ä¸­...")
    generator = torch.Generator("cuda").manual_seed(1024)
    
    # å‡†å¤‡StreamFlow
    stream.prepare(prompt, neg_prompt, num_inference_steps=4, guidance_scale=7.5)
    
    # ğŸ” æ·»åŠ UNetè°ƒç”¨ç»Ÿè®¡ï¼ˆç”¨äºè§‚å¯Ÿæ‰¹é‡å»å™ªæ•ˆæœï¼‰
    original_forward = stream.unet.forward
    unet_call_count = 0
    
    def count_unet_calls(*args, **kwargs):
        nonlocal unet_call_count
        unet_call_count += 1
        return original_forward(*args, **kwargs)
    
    stream.unet.forward = count_unet_calls
    
    # é¢„çƒ­ç”Ÿæˆ
    for i in range(5):
        unet_call_count = 0
        _ = stream.txt2img()
        if i == 0:
            print(f"   é¦–æ¬¡UNetè°ƒç”¨: {unet_call_count}æ¬¡")
        if i % 3 == 0:
            print(f"   é¢„çƒ­ {i+1}/5")
    
    print("âœ… é¢„çƒ­å®Œæˆ")
    
    # å¸§ç¼“å†²æµ‹è¯•è®¾ç½®
    output_dir = f"test42_real_batch_{'enabled' if USE_REAL_BATCH_DENOISING else 'disabled'}_output"
    os.makedirs(output_dir, exist_ok=True)
    
    # æµ‹è¯•ä¸åŒçš„ç”Ÿæˆæ¨¡å¼ï¼ˆä¿æŒtest25ç»“æ„ï¼‰
    test_modes = [
        {"name": "txt2img", "iterations": 50, "description": "æ–‡æœ¬åˆ°å›¾åƒç”Ÿæˆ"},
        {"name": "sequence", "iterations": 30, "description": "åºåˆ—ç”Ÿæˆï¼ˆæ¨¡æ‹Ÿè§†é¢‘å¸§ï¼‰"},
    ]
    
    all_results = {}
    total_unet_calls_all = 0
    
    for mode_config in test_modes:
        mode_name = mode_config["name"]
        iterations = mode_config["iterations"]
        description = mode_config["description"]
        
        print(f"\nğŸ¨ å¼€å§‹{description}æµ‹è¯• ({mode_name})...")
        print(f"ğŸ’¾ è¾“å‡ºç›®å½•: {output_dir}")
        print(f"ğŸ”¢ ç”Ÿæˆæ¬¡æ•°: {iterations}")
        
        results = []
        quality_samples = []  # ä¿å­˜ä¸€äº›æ ·æœ¬ç”¨äºè´¨é‡æ£€æŸ¥
        mode_unet_calls = 0
        
        # ç”Ÿæˆå¾ªç¯
        for i in range(iterations):
            unet_call_count = 0
            
            torch.cuda.synchronize()
            start_time = time.time()
            
            if mode_name == "txt2img":
                # æ ‡å‡†txt2imgç”Ÿæˆ
                sample = stream.txt2img()
            elif mode_name == "sequence":
                # åºåˆ—ç”Ÿæˆï¼šä½¿ç”¨å‰ä¸€å¸§ä½œä¸ºè¾“å…¥ï¼ˆæ¨¡æ‹Ÿè§†é¢‘ï¼‰
                if i == 0:
                    # ç¬¬ä¸€å¸§ä»txt2imgå¼€å§‹
                    sample = stream.txt2img()
                else:
                    # åç»­å¸§ä½¿ç”¨img2imgï¼ˆå¦‚æœæ”¯æŒçš„è¯ï¼‰
                    sample = stream.txt2img()  # æš‚æ—¶è¿˜æ˜¯ç”¨txt2img
            
            torch.cuda.synchronize()
            elapsed = time.time() - start_time
            results.append(elapsed)
            mode_unet_calls += unet_call_count
            
            # è®¡ç®—FPS
            img_per_sec = 1 / elapsed
            avg_fps = len(results) / sum(results)
            
            # ä¿å­˜å›¾åƒ
            output_path = os.path.join(output_dir, f"{mode_name}_{i:06d}.png")
            torchvision.utils.save_image(sample, output_path)
            
            # ä¿å­˜ä¸€äº›æ ·æœ¬ç”¨äºè´¨é‡å¯¹æ¯”
            if i in [0, 5, 10, 15, 20, iterations-1]:
                quality_samples.append((i, sample.clone()))
            
            # æ˜¾ç¤ºè¿›åº¦ï¼ˆåŠ å…¥UNetç»Ÿè®¡ï¼‰
            if i % 10 == 0 or i < 5:
                print(f"ğŸ–¼ï¸  {mode_name} {i+1:3d}/{iterations} | "
                      f"FPS: {img_per_sec:6.2f} | "
                      f"å¹³å‡FPS: {avg_fps:6.2f} | "
                      f"UNet: {unet_call_count} | "
                      f"ç”¨æ—¶: {elapsed:.3f}s")
        
        total_unet_calls_all += mode_unet_calls
        
        # æ¨¡å¼ç»Ÿè®¡ï¼ˆä¿æŒtest25ç»“æ„ï¼ŒåŠ å…¥UNetç»Ÿè®¡ï¼‰
        if results:
            avg_time = sum(results) / len(results)
            total_fps = len(results) / sum(results)
            min_time = min(results)
            max_time = max(results)
            avg_unet_calls_per_image = mode_unet_calls / len(results)
            
            print(f"\nğŸ“Š {description}æ€§èƒ½ç»Ÿè®¡")
            print("-" * 60)
            print(f"æ€»å›¾åƒæ•°:       {len(results)}")
            print(f"å¹³å‡ç”Ÿæˆæ—¶é—´:   {avg_time:.3f}s")
            print(f"æœ€å¿«æ—¶é—´:       {min_time:.3f}s ({1/min_time:.2f} FPS)")
            print(f"æœ€æ…¢æ—¶é—´:       {max_time:.3f}s ({1/max_time:.2f} FPS)")
            print(f"å¹³å‡FPS:        {total_fps:.2f}")
            print(f"ğŸ¯ å¹³å‡UNetè°ƒç”¨: {avg_unet_calls_per_image:.1f}")
            print(f"æ€»ç”¨æ—¶:         {sum(results):.2f}s")
            
            # æ‰¹é‡å»å™ªæ•ˆæœè¯„ä¼°
            if USE_REAL_BATCH_DENOISING:
                if avg_unet_calls_per_image <= 1.5:
                    print(f"   âœ… æµæ°´çº¿æ‰¹é‡å»å™ªç”Ÿæ•ˆï¼({avg_unet_calls_per_image:.1f}æ¬¡UNetè°ƒç”¨)")
                else:
                    print(f"   âš ï¸  æ‰¹é‡å»å™ªæ•ˆæœæœ‰é™ ({avg_unet_calls_per_image:.1f}æ¬¡UNetè°ƒç”¨)")
            else:
                print(f"   ğŸ“Š åŸå§‹StreamFlowåŸºå‡† ({avg_unet_calls_per_image:.1f}æ¬¡UNetè°ƒç”¨)")
            
            all_results[mode_name] = {
                "avg_time": avg_time,
                "total_fps": total_fps,
                "min_time": min_time,
                "max_time": max_time,
                "total_images": len(results),
                "avg_unet_calls": avg_unet_calls_per_image
            }
        
        # ç”Ÿæˆè´¨é‡æ ·æœ¬ç½‘æ ¼ï¼ˆä¿æŒtest25ç»“æ„ï¼‰
        if quality_samples:
            print(f"ğŸ¨ ç”Ÿæˆ{mode_name}è´¨é‡æ ·æœ¬ç½‘æ ¼...")
            # åˆ›å»ºæ ·æœ¬ç½‘æ ¼
            sample_tensors = [sample for _, sample in quality_samples]
            grid = torchvision.utils.make_grid(
                torch.cat(sample_tensors, dim=0), 
                nrow=3, 
                padding=2, 
                normalize=False
            )
            
            grid_path = os.path.join(output_dir, f"{mode_name}_quality_samples_grid.png")
            torchvision.utils.save_image(grid, grid_path)
            print(f"âœ… {mode_name}è´¨é‡æ ·æœ¬ç½‘æ ¼å·²ä¿å­˜: {grid_path}")
        
        quality_samples = []  # æ¸…ç©ºå‡†å¤‡ä¸‹ä¸€ä¸ªæ¨¡å¼
    
    # æ¢å¤UNetï¼ˆé‡è¦ï¼ï¼‰
    stream.unet.forward = original_forward
    
    # æ•´ä½“æ€§èƒ½å¯¹æ¯”ï¼ˆä¿æŒtest25ç»“æ„ï¼ŒåŠ å…¥UNetç»Ÿè®¡ï¼‰
    print(f"\nğŸ† å¸§ç¼“å†²æ€§èƒ½æ€»ç»“ ({'æ‰¹é‡å»å™ªå¯ç”¨' if USE_REAL_BATCH_DENOISING else 'åŸå§‹StreamFlow'})")
    print("=" * 80)
    print(f"å¸§ç¼“å†²å¤§å°: {FRAME_BUFFER_SIZE}")
    print(f"ğŸ¯ æ‰¹é‡å»å™ªæ¨¡å¼: {'âœ… æµæ°´çº¿å¹¶è¡Œ' if USE_REAL_BATCH_DENOISING else 'âŒ åŸå§‹é€æ­¥'}")
    print("-" * 80)
    print(f"{'æ¨¡å¼':<15} {'å¹³å‡FPS':<10} {'æœ€å¿«FPS':<10} {'UNetè°ƒç”¨':<10} {'å›¾åƒæ•°':<8}")
    print("-" * 80)
    
    for mode_name, stats in all_results.items():
        fastest_fps = 1.0 / stats["min_time"]
        print(f"{mode_name:<15} {stats['total_fps']:<10.2f} {fastest_fps:<10.2f} {stats['avg_unet_calls']:<10.1f} {stats['total_images']:<8}")
    
    # æ‰¹é‡å»å™ªæ•ˆæœåˆ†æ
    print(f"\nğŸ’¡ æ‰¹é‡å»å™ªæ•ˆæœåˆ†æ:")
    print(f"   ğŸ“Š å½“å‰é…ç½®:")
    print(f"      - å¸§ç¼“å†²å¤§å°: {FRAME_BUFFER_SIZE}")
    print(f"      - æ‰¹é‡å»å™ª: {'å¯ç”¨' if USE_REAL_BATCH_DENOISING else 'ç¦ç”¨'}")
    
    if USE_REAL_BATCH_DENOISING:
        # åˆ†ææ‰¹é‡å»å™ªæ•ˆæœ
        avg_unet_overall = total_unet_calls_all / sum(stats['total_images'] for stats in all_results.values())
        if avg_unet_overall <= 1.5:
            print(f"      âœ… æµæ°´çº¿æ‰¹é‡å»å™ªæˆåŠŸï¼")
            print(f"         - å¹³å‡UNetè°ƒç”¨: {avg_unet_overall:.1f}æ¬¡ï¼ˆé¢„æœŸ1æ¬¡ï¼‰")
            print(f"         - ç†è®ºåŠ é€Ÿ: {4.0 / avg_unet_overall:.1f}x")
        else:
            print(f"      âš ï¸  æ‰¹é‡å»å™ªæ•ˆæœæœ‰é™")
            print(f"         - å¹³å‡UNetè°ƒç”¨: {avg_unet_overall:.1f}æ¬¡ï¼ˆç›®æ ‡1æ¬¡ï¼‰")
        
        print(f"      ğŸš€ æµæ°´çº¿ä¼˜åŠ¿:")
        print(f"         - ä¿æŒPeRFlowç®—æ³•å®Œæ•´æ€§")
        print(f"         - ç‰¹åˆ«é€‚åˆè¿ç»­ç”Ÿæˆåœºæ™¯")
        print(f"         - 4å¼ å›¾ç‰‡ä¸åŒé˜¶æ®µå¹¶è¡Œå¤„ç†")
    else:
        avg_unet_original = total_unet_calls_all / sum(stats['total_images'] for stats in all_results.values())
        print(f"      ğŸ“Š åŸå§‹StreamFlowåŸºå‡†:")
        print(f"         - å¹³å‡UNetè°ƒç”¨: {avg_unet_original:.1f}æ¬¡ï¼ˆæ ‡å‡†4æ¬¡ï¼‰")
        print(f"         - ä¸test25è¡Œä¸ºå®Œå…¨ç›¸åŒ")
        print(f"         - é€æ­¥å»å™ªï¼Œè´¨é‡ç¨³å®š")
    
    # å¸§ç¼“å†²æ•ˆæœåˆ†æï¼ˆä¿æŒtest25é€»è¾‘ï¼‰
    if FRAME_BUFFER_SIZE == 1:
        print(f"      - æ— ç¼“å†²æ¨¡å¼ï¼šæ¯å¸§ç‹¬ç«‹ç”Ÿæˆï¼Œå»¶è¿Ÿæœ€ä½")
        print(f"      - é€‚åˆï¼šå•å¼ å›¾åƒç”Ÿæˆã€æœ€ä½å»¶è¿Ÿéœ€æ±‚")
    elif FRAME_BUFFER_SIZE <= 4:
        print(f"      - å°ç¼“å†²æ¨¡å¼ï¼šå¹³è¡¡å»¶è¿Ÿå’Œæµç•…åº¦")
        print(f"      - é€‚åˆï¼šå®æ—¶åº”ç”¨ã€è½»é‡çº§æµå¼ç”Ÿæˆ")
    else:
        print(f"      - å¤§ç¼“å†²æ¨¡å¼ï¼šæ›´é«˜çš„æµç•…åº¦ï¼Œä½†å»¶è¿Ÿå¢åŠ ")
        print(f"      - é€‚åˆï¼šé«˜è´¨é‡è§†é¢‘ç”Ÿæˆã€æ‰¹é‡å¤„ç†")
    
    # ä¸ä¸åŒbuffer sizeçš„å¯¹æ¯”å»ºè®®ï¼ˆä¿æŒtest25é€»è¾‘ï¼‰
    print(f"\nğŸ”„ å»ºè®®æµ‹è¯•ä¸åŒé…ç½®:")
    print(f"   - ä¿®æ”¹ USE_REAL_BATCH_DENOISING = False æµ‹è¯•åŸå§‹StreamFlow")
    print(f"   - buffer_size=1: æœ€ä½å»¶è¿Ÿ")
    print(f"   - buffer_size=2: è½»é‡çº§æµå¼")
    print(f"   - buffer_size=4: å¹³è¡¡æ¨¡å¼")
    print(f"   - buffer_size=8: é«˜æµç•…åº¦")
    
    print(f"\nğŸ‰ æµ‹è¯•å®Œæˆï¼")
    print(f"ğŸ“ æ‰€æœ‰å›¾åƒå·²ä¿å­˜åˆ°: {output_dir}")
    print(f"ğŸ” è¯·æ£€æŸ¥ä¸åŒæ¨¡å¼çš„å›¾åƒè´¨é‡å’Œè¿ç»­æ€§")
    
    if USE_REAL_BATCH_DENOISING:
        print(f"ğŸ’¡ ç‰¹åˆ«æé†’ï¼šæµæ°´çº¿æ‰¹é‡å»å™ªåœ¨è¿ç»­ç”Ÿæˆæ—¶æ•ˆæœæœ€æ˜æ˜¾")
    
    return {
        "frame_buffer_size": FRAME_BUFFER_SIZE,
        "use_real_batch_denoising": USE_REAL_BATCH_DENOISING,
        "results": all_results,
        "output_dir": output_dir,
        "total_unet_calls": total_unet_calls_all,
        "config": {
            "use_tiny_vae": USE_TINY_VAE,
            "vae_decode_method": VAE_DECODE_METHOD,
            "acceleration": ACCELERATION,
            "use_denoising_batch": USE_DENOISING_BATCH,
            "do_add_noise": DO_ADD_NOISE
        }
    }


if __name__ == "__main__":
    # è¿è¡Œå¸§ç¼“å†²æµ‹è¯•ï¼ˆåŠ å…¥çœŸæ­£çš„æ‰¹é‡å»å™ªåŠŸèƒ½ï¼‰
    results = run_perflow_frame_buffer_test()
    
    print(f"\nğŸ† Test42æµ‹è¯•æ€»ç»“:")
    print(f"å¸§ç¼“å†²å¤§å°: {results['frame_buffer_size']}")
    print(f"æ‰¹é‡å»å™ª: {'å¯ç”¨' if results['use_real_batch_denoising'] else 'ç¦ç”¨'}")
    print(f"æ€»UNetè°ƒç”¨: {results['total_unet_calls']}")
    print(f"è¾“å‡ºç›®å½•: {results['output_dir']}")
    
    if results['use_real_batch_denoising']:
        total_images = sum(stats['total_images'] for stats in results['results'].values())
        avg_unet = results['total_unet_calls'] / total_images if total_images > 0 else 0
        if avg_unet <= 1.5:
            print(f"ğŸš€ æµæ°´çº¿æ‰¹é‡å»å™ªæˆåŠŸï¼å¹³å‡UNetè°ƒç”¨: {avg_unet:.1f}æ¬¡")